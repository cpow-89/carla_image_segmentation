{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create your own image segmentation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Tested on Windows with carla 0.9.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Start Carla by running CarlaUE4.exe\n",
    "\n",
    "### Step 2: Run cmd from within the repo folder and activate your conda environment\n",
    "\n",
    "```activate carla```\n",
    "\n",
    "### Step 3: Spawn some Npc's by running the following command\n",
    "\n",
    "```python spawn_npc.py```\n",
    "\n",
    "I used the following arguments.\n",
    "\n",
    "```python spawn_npc.py -n 30 --safe```\n",
    "\n",
    "-n 30 means that we spawn 30 random Npc's.\n",
    "\n",
    "-- safe means to avoid spawning vehicles prone to accidents.\n",
    "\n",
    "There are more optional arguments which you can check out using the following command:\n",
    "\n",
    "```python spawn_npc.py -h```\n",
    "\n",
    "### Step 4: Run cmd from within the repo folder again and activate your conda environment\n",
    "\n",
    "```activate carla```\n",
    "\n",
    "### Step 5: Collect your data by running the following command\n",
    "\n",
    "```python collect_train_data.py```\n",
    "\n",
    "I used the following arguments.\n",
    "\n",
    "```python collect_train_data.py -n 30 -d 180```\n",
    "\n",
    "-n 30 means that we collect data from 30 random spawn points\n",
    "\n",
    "-d 180 means that we let the ego vehicle drive in autopilot for 180 seconds\n",
    "\n",
    "##### How this script works:\n",
    "\n",
    "This script creates an ego vehicle with a rgba and a semantic segmentation camera attached to it at front centre.\n",
    "<img src=\"doc_images/rgba.png\">\n",
    "\n",
    "The script spawns the ego vehicle in a unique position. The position is randomly selected.\n",
    "The vehicle then starts to drive using autopilot and collect data for -d seconds. The collected rgba images are saved to \"./output/images\", and the collected semantic segmentation masks are saved to \"./output/labels\"\n",
    "After that, the ego vehicle will respawn on another unique, randomly selected position. This will be repeated -n times.\n",
    "\n",
    "This means that this script tries to collect -n * -d/2 images -> we divide by two cause in ego_camera_sensors.json I specified the tick of the camera to be 2 seconds. But you can change this if you want. \n",
    "\n",
    "### Step 6: Clean up file names\n",
    "\n",
    "The collected images and labels are named with the following naming convention run{}_fr_{}.png. \n",
    "run is the run or spawn id. This means that images that were collected when the ego vehicle was spawned the second time are named with run1. fr stands for frame. I used the frame information to generate unique file names. \n",
    "\n",
    "When we inspect the collected images and labels we can see, that they have slightly of frame ids. That is due to the fact that we had to use two separate cameras to collect the data. So the images are slightly off. But in most cases, this is such a small offset that it is acceptable. However, we now need to synch the label and image file names. You can do this by running the following helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from clean_up_dataset import clean_up_file_names_preserving_run_id\n",
    "\n",
    "clean_up_file_names_preserving_run_id(os.path.join(\".\", \"output\", \"images\"))\n",
    "clean_up_file_names_preserving_run_id(os.path.join(\".\", \"output\", \"labels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper function will replace the frame id with an uprising id.\n",
    "\n",
    "### Step 7: Clean up the collected data\n",
    "\n",
    "This is the annoying part. Because the autopilot tries to respect traffic rules, it will stop on red lines or stop signs. In this case, we will have some images that are nearly identical. We need to remove them. For that, you have to take a look at all images within the \"images\" folder and delete the ones that you think are invalid.\n",
    "\n",
    "In my case, I had 1700 images and ended up with 1206.\n",
    "\n",
    "### Step 8: Create the dataset\n",
    "\n",
    "We now need to create our dataset. Therefore we will copy all valid image/label pairs to a new folder called dataset. Then we will select a number of runs to be our validation set. To do this, we save all filenames of the selected runs to a txt file. This can all be done by using the following helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_up_dataset import copy_valid_image_files_to_dataset\n",
    "from clean_up_dataset import create_validation_set_file\n",
    "\n",
    "copy_valid_image_files_to_dataset(\"images\")\n",
    "copy_valid_image_files_to_dataset(\"labels\")\n",
    "create_validation_set_file([\"2\", \"9\", \"13\", \"19\", \"27\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Done\n",
    "\n",
    "ThatÂ´s it. We are done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carla] *",
   "language": "python",
   "name": "conda-env-carla-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}